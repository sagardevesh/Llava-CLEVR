#!/bin/bash
#SBATCH --job-name=llava_inference_clevr
#SBATCH --partition=a40
#SBATCH --account=deadline
#SBATCH --qos=deadline
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:1          # 1 GPU (adjust if you want more)
#SBATCH --mem=60G             # 32 GB CPU RAM (adjust as needed)
#SBATCH --time=24:00:00       # up to 24 hours
#SBATCH --output=logs/llava-clevr-%j.out

# 1) [Optional] Load modules if your cluster uses environment modules
module load anaconda/3

export PYTHONNOUSERSITE=1

# 3) Go to directory containing run_llava_inference.py
cd /fs01/home/sdevesh/Llava

# Use 'conda run' to ensure we run in llava-env:
srun conda run -n llava-env python run_llava_inference.py \
    --model-dir /fs01/model-weights/llava-1.5-13b-hf \
    --question-file /fs01/home/sdevesh/Llava/filtered_CLEVR_test_questions.json \
    --image-dir /fs01/datasets/CLEVR/CLEVR_v1.0/images/test \
    --out-file llava_clevr_test_results.json \
    --device cuda \
    --max-new-tokens 128 \
    --temperature 0.1 \
    --device-map-auto \
    --batch-size 4
